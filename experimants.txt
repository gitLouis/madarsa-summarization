1. Basic sentence splitting (using NLTK Sentence Tokenizer)
    - Try avoiding splitting so the topic modeling will run over all data
    - Try a more advanced sentence splitter (llm based / classical nlp)


2. Topic Modeling (using BERTopic):
    * Sentence Embedding (using HF sentence-transformers-alphabert)
    * Dimensionality reduction (using UMAP)
    * Clustering (using HDBSCAN)
    * Topic representation (using BERTopic normalized-tfidf + LLM outside of BERTopic)
        - use LLM inside BERTopic?

3. Topic Summarizing (using LLM):
    * Batch splitting 
    * LLM Summarization for each batch
    * LLM Summarization of summaries
      
    - try Stuff vs Map-Reduce (current, but with separate prompts) vs Iterative Refinement approaches